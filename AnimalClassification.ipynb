{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf00081-c3b7-4bd7-88aa-92d7c0a34563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import shutil\n",
    "from sklearn.metrics import accuracy_score , confusion_matrix\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee5945b-0952-4ce1-b188-a25b36676b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available(): \n",
    " dev = \"cuda:0\" \n",
    "else: \n",
    " dev = \"cpu\" \n",
    "device = torch.device(dev) \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36de0069-0036-4f3d-a95b-15b0df0dd418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AnimalDataset(Dataset):\n",
    "    def __init__(self, root = \"animals_v2/animals\" , train = True , transform = None):\n",
    "        self.categories = [\"butterfly\", \"cat\", \"chicken\", \"cow\", \"dog\", \"elephant\", \"horse\", \"sheep\", \"spider\", \"squirrel\"]\n",
    "        if train : \n",
    "            data_path = os.path.join(root , \"train\")\n",
    "        else:\n",
    "            data_path = os.path.join(root , \"test\")\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for category in self.categories:\n",
    "            category_path = os.path.join(data_path , category)\n",
    "            for image_name in os.listdir(category_path):\n",
    "                image_path = os.path.join(category_path, image_name)\n",
    "                self.image_paths.append(image_path)\n",
    "                self.labels.append(self.categories.index(category))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        image = cv2.imread(self.image_paths[item])\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = self.labels[item]\n",
    "        return image , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "427903ae-e413-4566-bcbf-e418708af81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Resize((256,256)),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03eaa661-ae15-4416-b8a0-f61de2d900d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_set = AnimalDataset(train = True , transform = data_transform)\n",
    "test_set = AnimalDataset(train = False , transform = data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c149f2d-27d3-4e67-8f96-0526f0a26dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23699"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea36ffd-e4ee-4c3d-9925-225cd9e50f30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set , batch_size = 16 , shuffle = True , drop_last = True)\n",
    "test_loader = DataLoader(test_set , batch_size = 16 , shuffle = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a29d941-17d5-4d3f-b2bc-eaf1402234d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(train_set.categories)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00b92cfc-295a-46b2-b8ca-2d749b0e3031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class My_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride = 2)\n",
    "        )#126\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride = 2)\n",
    "        )#61\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride = 2)\n",
    "        )#28\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride = 2)\n",
    "        )#\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=0),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride = 2)\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4*4*256, 2048),\n",
    "            nn.ReLU())\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(2048, 4096),\n",
    "            nn.ReLU())\n",
    "        self.fc2= nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc3= nn.Sequential(\n",
    "            nn.Linear(4096, num_classes))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac45579b-1e85-4c37-9c01-b9cd30e623c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2957919a-e58d-45be-9e0e-730563985555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = My_Model(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "300a6c66-f7d0-412c-9fc4-16d8cfcf586f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum = 0.7)\n",
    "num_epochs = 80\n",
    "num_iter = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "453a1fde-4eb7-4b6c-a2d7-f7c0a83b61a4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m log_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(log_path):\n\u001b[0;32m      3\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(log_path)\n\u001b[0;32m      4\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(log_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "log_path = \"tensorboard\"\n",
    "if os.path.isdir(log_path):\n",
    "    shutil.rmtree(log_path)\n",
    "os.mkdir(log_path)\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "if not os.path.isdir(\"trained_models_1\"):\n",
    "    os.mkdir(\"trained_models_1\")\n",
    "writer = SummaryWriter(log_path)\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for i, (images , labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred , labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_value = loss.item()\n",
    "        print(\"Epoch {}/{} | Iteration {}/{} | Loss value : {}\".format(epoch + 1 , num_epochs , i , num_iter, loss_value))\n",
    "        losses.append(loss_value)\n",
    "        writer.add_scalar(\"Train/Loss\" , np.mean(losses), epoch*num_iter + i)\n",
    "\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    all_predictions = []\n",
    "    all_gts = []\n",
    "    with torch.inference_mode():\n",
    "        for i, (images , labels) in enumerate(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            pred = model(images)\n",
    "            max_idx = torch.argmax(pred , 1)\n",
    "            loss = criterion(pred , labels)\n",
    "            losses.append(loss.item())\n",
    "            all_gts.extend(labels.tolist())\n",
    "            all_predictions.extend(max_idx.tolist())\n",
    "    writer.add_scalar(\"Val/Loss\" , np.mean(losses), epoch)\n",
    "    acc = accuracy_score(all_gts , all_predictions)\n",
    "    writer.add_scalar(\"Val/Accuracy\", acc , epoch)\n",
    "    conf_matrix = confusion_matrix(all_gts , all_predictions)\n",
    "    checkpoint = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"epoch\": epoch,\n",
    "                \"best_acc\": best_acc,\n",
    "            }\n",
    "    torch.save(checkpoint, os.path.join(\"trained_models_1\", \"last.pt\"))\n",
    "    if acc > best_acc:\n",
    "        torch.save(checkpoint, os.path.join(\"trained_models_1\", \"best.pt\"))\n",
    "        best_acc = acc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82e6a5-d158-4120-92cc-3d66c56aebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"sheep.jpg\")\n",
    "image = cv2.resize(image, (256, 256))\n",
    "image = np.transpose(image, (2, 0, 1))\n",
    "image = image / 255\n",
    "image = np.expand_dims(image, 0)\n",
    "image = torch.from_numpy(image).to(device).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d05a9c3-a6a1-41f5-ae6f-6d35ec5d5b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f29d9062-eb43-46c7-b529-90e28d7a754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    pred = model(image).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a098d3b9-b2ad-46d0-9847-7ed990ca9543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6746e-24, 0.0000e+00, 1.4013e-45,\n",
       "         0.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29e446f7-f64d-4886-993d-d7580436dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d24dc657-a03b-4061-b7a6-c35707329437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7, device='cuda:0')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9fceab36-57a7-4fb7-a7e9-f3bd78d2da44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sheep'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.categories[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b7d02ec2-0617-4070-be18-273c802907c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['butterfly',\n",
       " 'cat',\n",
       " 'chicken',\n",
       " 'cow',\n",
       " 'dog',\n",
       " 'elephant',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'spider',\n",
       " 'squirrel']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9419a89-13e2-4785-a90e-febffbd66fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
